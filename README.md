# CLERA - Cellular Latent Equations Representation and Analysis

CLERA is a novel end-to-end computational framework designed to uncover parsimonious dynamical models and identify active gene programs from single-cell RNA sequencing data. This repository contains the code used to train and demonstrate CLERA on three scRNA datasets.

## Usage
### Training
Navigate to the appropriate example dataset directory (e.g., Pancreas or Bone_Marrow) under Examples to start the training. Each directory contains two notebooks. preprocess.ipynb helps in generating the training data. Modify/Add the preprocessing params dictionary for more control over the training data. train_model.ipynb loads the data generated by preprocess.ipynb (sample pickle files with preprocessed data is shared and can be used directly) Modify the params dictionary for more control over the training trajectory.

Every experiment is repeated by 'num_instance' number. The experiment outputs are stored in the relevant directory

## Training Parameters

#### Model Settings
- `latent_dim`              # Dimensionality of the latent space
- `input_dim`               # Input dimension (number of genes)
- `model_order`             # Order of the model (Currently only model_order=1 is supported)


#### SINDy Library (Boolean variables)
- `include_exp`             # Include exponential terms
- `include_reciprocal_func` # Include reciprocal functions
- `include_constant`        # Include constant term in SINDy library
- `poly_order`              # Polynomial order for SINDy

#### Sequential Thresholding Parameters
- `sequential_thresholding` # Enable sequential thresholding
- `coefficient_threshold`   # Threshold for coefficients
- `threshold_frequency`     # Frequency of threshold updates
- `coefficient_mask`        # The terms in the SINDy library to mask out in the beginning

#### Loss Function Weighting
- `loss_weight_decoder`         # Weight for the decoder loss (reconstruction error)
- `loss_weight_sindy_z`         # Weight for SINDy term z
- `loss_weight_sindy_x`         # Weight for SINDy term x
- `loss_weight_sindy_regularization` # Regularization weight for SINDy terms
- `autoencoder_regularization`  # Regularization weight for autoencoder

#### Neural Network Architecture
- `activation`            # Activation function (e.g., 'relu', 'sigmoid')
- `widths`                # List of layer widths for encoder and decoder

#### Training Parameters
- `learning_rate`         # Learning rate for optimization
- `batch_size`            # Size of each training batch (same as dataset size in this case)
- `max_epochs`            # Maximum number of training epochs
- `refinement_epochs`     # Number of additional refinement epochs
- `terms`                 # Early stopping criteria based on number of active terms

#### Classification Parameters
- `classify`              # Enable classification network
- `classifier_widths`     # List of layer widths for classifier network
- `num_classes`           # Number of classes for classification
- `loss_class`            # Weight for classification loss

#### Coefficient Initialization
- `coefficient_initialization`  # Method for initializing SINDy coefficients (example 'specified', 'normal'). In case 'specified' is used, 'init_cefficient' takes the innitialization values
- `init_coefficients`           # Random initialization of coefficients in the SINDy library

#### Saving Results
- `save_folder`           # Directory where experiment results are saved


### Inference
After training, navigate to the Inference directory to:
1. Select the best experiment
2. Find SHAP values for the best experiment
3. Create interaction networks based on the learned latent variables
Make sure to choose the appropriate path variables for inference based on the dataset used for training.

## Installation
This code is supported with Python 3.6.7 Run the following command to install the required dependencies:
pip install -r requirements.txt


## Structure

```bash
.
├── src
│   ├── Training scripts
│   ├── Utility Files
├── Examples
│   ├── Pancreas
│   ├── Bone_Marrow
│   ├── SERGIO
|   ├── Inference
        ├── Choose Best Experiment
        ├── Find SHAP values
        └── Create Interaction Network
